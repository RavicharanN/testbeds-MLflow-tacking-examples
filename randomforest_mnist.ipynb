{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import mlflow\n",
        "    print(\"MLflow is already installed\")\n",
        "except ImportError:\n",
        "    print(\"MLflow not found. Installing...\")\n",
        "    !pip install mlflow"
      ],
      "metadata": {
        "id": "OI-dBfNlfenx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5KHJ9iYff_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "nSaTBu27fjQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup  MLFlow tracking\n",
        "\n",
        "You will replace the link with your actual MLFlow trackering server.\n",
        "\n",
        "In this example, we will explicitly log the parameters rather than using the autlog feature that MLFlow comes with\n"
      ],
      "metadata": {
        "id": "7T8F0uXlmeCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_tracking_uri(\"http://tracking_server_host:port_num\")\n",
        "mlflow.start_run()"
      ],
      "metadata": {
        "id": "fv8I0Y0em5Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the train and test sets\n"
      ],
      "metadata": {
        "id": "o6n45XPFnavk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml(\"mnist_784\", version=1)\n",
        "X = mnist.data.astype(\"float32\") / 255.0  # Normalize pixel values\n",
        "y = mnist.target.astype(\"int64\")"
      ],
      "metadata": {
        "id": "PDOHSk8mnqp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "KMS3nG6Nn0eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model and manually log the parameters"
      ],
      "metadata": {
        "id": "1LxznLxerOX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = 100\n",
        "model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)"
      ],
      "metadata": {
        "id": "Y2eXpKMfn77c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log the number of estimators"
      ],
      "metadata": {
        "id": "fCLFJCTgrUn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.log_param(\"n_estimators\", n_estimators)\n"
      ],
      "metadata": {
        "id": "yIjQ2SV6rTfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "cglrQrwxoMwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log the accuracy and the model"
      ],
      "metadata": {
        "id": "Dvd8sL9srg0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Log metrics\n",
        "mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "# Log the model\n",
        "mlflow.sklearn.log_model(model, \"random_forest\")"
      ],
      "metadata": {
        "id": "i0J1d3ySoPIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "Dw2qdWvFrs04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# View the logged run"
      ],
      "metadata": {
        "id": "93ddPPyOpieA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_id = \"YOUR_RUN_ID\"  # You can find run ID in the Tracking UI\n",
        "artifact_path = \"model\"\n",
        "\n",
        "# Download artifact via the tracking server\n",
        "mlflow_artifact_uri = f\"runs://{run_id}/{artifact_path}\"\n",
        "local_path = mlflow.artifacts.download_artifacts(mlflow_artifact_uri)\n",
        "\n",
        "# Load the model\n",
        "model = mlflow.sklearn.load_model(local_path)"
      ],
      "metadata": {
        "id": "Qw33JeR4plCc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}